<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MVWGMQ0HDM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MVWGMQ0HDM');
</script>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <title>Ben Lahner</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="style.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="normalize.css">
  <link rel="stylesheet" href="skeleton.css">

  <!-- Favicn
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/CSAIL_Primary_Regular_RGB.png">

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <div class="row" style="margin-top: 10%">
        <div class="seven columns">
            <h2>Ben Lahner</h2>
            <h5>Massachusetts Institute of Technology</h5>
            <p><b>Email</b>: blahner (at) mit (dot) edu
                <br>
                <a href="https://www.linkedin.com/in/benlahner/" target="_blank">Linkedin profile</a>,
                <!-- <b>CV</b>: <a href="http://www.mit.edu/~bsturt/brads_cv.pdf">PDF</a>,  -->
                <a href="https://scholar.google.com/citations?user=goKPqBcAAAAJ&hl=en&oi=ao" target="_blank">Google scholar</a>,
                </p>
        </div>
        <div class="four columns">
            <img src="images/headshot.jpg" width="120%">
        </div>
    </div>
    <div class="row" style="margin-top: 5%"> </div>


    <h4> About </h4>
    <p>I am a fourth-year PhD student in MIT's <a href="https://www.eecs.mit.edu/" target="_blank">Electrical Engineering and Computer Science</a> (EECS) department 
        and <a href="https://www.csail.mit.edu/" target="_blank">Computer Science and Artificial Intelligence</a> (CSAIL) lab at MIT, where I am advised by 
        <a href="http://olivalab.mit.edu/audeoliva.html" target="_blank">Aude Oliva</a>. I am a computational neuroscientist where I study how both humans and machines process visual
        and auditory information. Towards this aim, I am actively engaged in the collection of human neuroimaging data (MEG and (f)MRI), the analysis of neural data, and 
        the implementation of state-of-the-art machine learning and deep learning models. I have recent industry experience at
        <a href="https://www.regeneron.com/" target="_blank">Regeneron Pharmaceuticals</a> and 
        <a href="https://azure.microsoft.com/en-us/services/cognitive-services/#features" target="_blank">Microsoft</a>, 
        where I was able to apply these skills with a clinical focus and product focus, respectively. I aadditionally have a focus in medical device design and manufacturing, where 
        I am an inventor in a patent-pending eye drop assist device.
        <br>
        <br>
        Prior to joining MIT, I graduated from Boston University with a B.S. in biomedical engineering. While there, I was first introduced to the world of
        research through <a href="https://sites.bu.edu/reinhartlab/" target="_blank">Professor Robert Reinhart</a> and 
        <a href="https://www.ndlbu.org/" target="_blank">Professor John White</a>. After graduating from Boston University, I joined MIT on a PhD track where I subsequently earned
        a M.S. degree in EECS in 2022.
        <br>
        <br>
        Visit my informal, non-academic <a href="https://medium.com/@benlahner" target="_blank">blog</a> where I write about whatever I find interesting at the moment.
    </p>

    <hr>

    <h4>Publications</h4>
    <ul>    
        <li>
            BOLD Moments: modeling short visual events through a video fMRI dataset and metadata.
            <br>
            <b>Benjamin Lahner</b>, Kshitij Dwivedi, Polina Iamshchinina, Monika Graumann, Alex Lascelles, Gemma Roig, Alessandro Thomas Gifford, Bowen Pan, SouYoung Jin, Ratan Murty, Kendrick Kay, Aude Oliva+, Radoslaw Cichy+
            <br>
            In Progress
            <br>            
            <a href="http://algonauts.csail.mit.edu/" target="_blank">Project Page</a> -
            <a href="https://www.biorxiv.org/content/10.1101/2023.03.12.530887v1" target="_blank">bioRxiv</a>
        </li>    
        <li>
            Cochlea to categories: The spatiotemporal dynamics of semantic auditory representations.
            <br>
            Matthew X. Lowe*, Yalda Mohsenzadeh*, <b>Benjamin Lahner</b>, Ian Charest, Aude Oliva and Santani Teng.
            <br>
            Cognitive Neuropsychology, 2022; doi:10.1080/02643294.2022.2085085
            <br>
            <a href="https://cochleatocategories.csail.mit.edu/" target="_blank">Project Page</a> -
            <a href="pdf/Cochlea to categories- The spatiotemporal dynamics of semantic auditory representations.pdf" target="_blank">PDF</a> -
            <a href="https://www.youtube.com/watch?v=Qhq_CSssQe8" target="_blank">Fusion Video</a>
        </li>
        <li>
            The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of Natural Scenes.
            <br>
            Allesandro T. Gifford, <b>Benjamin Lahner</b>, Sari Saba-Sadiya, Martina G. Vilas, Alex Lascelles, Aude Oliva, Kendrick Kay, Gemma Roig, Radoslaw M. Cichy
            <br>
            arXiv 2023, arXiv:2301.03198
            <br>
            <a href="http://algonauts.csail.mit.edu/" target="_blank">Project Page</a> - 
            <a href="pdf/The Algonauts Project 2023 Challenge- How the Human Brain Makes Sense of Natural Scenes.pdf" target="_blank">PDF</a>

        </li>   
        <li>
            The Algonauts Project 2021 Challenge: How the Human Brain Makes Sense of a World in Motion.
            <br>
            Radoslaw Martin Cichy, Kshitij Dwivedi, <b>Benjamin Lahner</b>, Alex Lascelles, Polina Iamshchinina, M Graumann, Alex Andonian, NAR Murty, K Kay, Gemma Roig, Aude Oliva
            <br>
            arXiv 2021, arXiv:2104.13714
            <br>
            <a href="http://algonauts.csail.mit.edu/2021/index.html" target="_blank">Project Page</a> - 
            <a href="pdf/The Algonauts Project 2021 Challenge- How the Human Brain Makes Sense of a World in Motion.pdf" target="_blank">PDF</a>

        </li>        
        <li>
            Emergence of visual center-periphery spatial organization in deep convolutional neural networks.
            <br>
            Yalda Mohsenzadeh, Caitlin Mullin, <b>Benjamin Lahner</b>, and Aude Oliva.
            <br>
            Scientific Reports 2020, 10, 4638; doi:10.1038/s41598-020-61409-0
            <br>
            <a href="http://topographicaldcnn.csail.mit.edu/" target="_blank">Project Page</a> -
            <a href="pdf/Emergence of Visual CenterPeriphery Spatial Organization in Deep Convolutional Neural Networks.pdf" target="_blank">PDF</a>

        </li>
        <li>
            Reliability and generalizability of similarity-based fusion of fMRI and MEG data in the ventral and dorsal visual streams.
            <br>
            Yalda Mohsenzadeh*, Caitlin Mullin*, <b>Benjamin Lahner</b>, Radoslaw Cichy, and Aude Oliva.
            <br>
            Vision 2019, 3, 8; doi:10.3390/vision3010008
            <br>
            <a href="http://twinsetfusion.csail.mit.edu/" target="_blank">Project Page</a> -
                <a href="pdf/reliability_and_generalizability_of_similarity_vision2019.pdf" target="_blank">PDF</a> -
                <a href="https://www.youtube.com/watch?v=5XlOCUlOyN0&feature=youtu.be" target="_blank">Fusion Video</a>
        </li>

        <li>
            The Algonauts Project: A platform for communication between the sciences of biological and artificial intelligence.
            <br>
            Radoslaw Martin Cichy, Gemma Roig, Alex Andonian, Kshitij Dwivedi, <b>Benjamin Lahner</b>, Alex Lascelles, Yalda Mohsenzadeh, Kandan Ramakrishnan, 
            and Aude Oliva.
            <br>
            arXiv 2019, arXiv:1905.05675
            <br>
            <a href="http://algonauts.csail.mit.edu/2019/index.html" target="_blank">Project Page</a> -
                <a href="pdf/the_algonauts_project_a_platform_arxiv2019.pdf" target="_blank">PDF</a>
        </li>
        <li>
            Tracking the Spatio-Temporal Neural Trace of Memorability.
            <br>
            <b>Benjamin Lahner</b>*, Caitlin Mullin*, Yalda Mohsenzadeh*, and Aude Oliva.
            <br>
            In Progress
            <br>
            <a href="https://youtu.be/jpK9_9CLCcE" target="_blank">Fusion Video</a>
        </li>
        <li>
            Machine learning analysis of a digital insole versus clinical standard gait assessments for digital endpoint development.
            <br>
            Matthew F. Wipperman*, Allen Z. Lin*, Kaitlyn Gayvert*, <b>Benjamin Lahner</b>, Selin Somersan-Karakaya, Xuefang Wu, Joseph Im, 
            Minji Lee, Bharatkumar Koyani, Ian Setliff, Malika Thakur, Daoyu Duan, Aurora Breazna, Fang Wang, Wei Keat Lim, Yamini Patel, 
            Mickey Atwal, Jennifer D. Hamilton, Clo Huyghues-Despointes, Oren Levy, Andreja Avbersek, Rinol Alaj, Sara C. Hamon, Olivier Harari.
            <br>
            medRxiv 2022; doi: https://doi.org/10.1101/2022.10.05.22280750
            <br>
            Under review
            <br>
            <a href="https://www.medrxiv.org/content/10.1101/2022.10.05.22280750v1" target="_blank">medRxiv</a>
        </li>
        <li>
            Theta phase specific modulation of hippocampal memory neurons.
            <br>
            Bahar Rahsepar, Jad Noueihed, Jacob F. Norman, <b>Benjamin Lahner</b>, Melanie H. Quick, Kevin Ghaemi, Aashna Pandya, Fernando R. Fernandez, Steve Ramirez, and John A. White
            <br>
            bioRxiv 2022; doi: https://doi.org/10.1101/2022.10.27.513992
            <br>
            Under review
            <br>
            <a href="https://www.biorxiv.org/content/10.1101/2022.10.27.513992v1.full" target="_blank">bioRxiv</a>
        </li>
    </ul>

    <hr>

    <h4>Selected Conference Abstracts</h4>
    <ul>
        <li>
            Modality-specific parameters and interference contribute to better-fitting bimodal associative learning models.
            <br>
            Han D. Huang, Frederik R. Baumgardt, <b>Benjamin Lahner</b>, Robert M. G. Reinhart.
            <br>
            Society for Neuroscience, Virtual (2021)
        </li>
        <li>
            The Emergence of Early Sound Categorical Responses in the Human Brain.
            <br>
            <b>Benjamin Lahner</b>, Santani Teng, Matthew X. Lowe, Ian Charest, Aude Oliva, Yalda Mohsenzadeh.
            <br>
            CNS, Boston, MA (2020)
        </li>
        <li>
            The Emergence of Early Sound Categorical Responses in the Human Brain.
            <br>
            <b>Benjamin Lahner</b>, Santani Teng, Matthew X. Lowe, Ian Charest, Aude Oliva, Yalda Mohsenzadeh.
            <br>
            NeurIPS SVRHM Workshop, Vancouver, Canada (2019)
        </li>
        <li>
            Assessing Reproducibility of MEG and fMRI Data Fusion Method in Neural Dynamics of Object Vision.
            <br>
            <b>Benjamin Lahner</b>, Yalda Mohsenzadeh, Caitlin Mullin, Radoslaw Cichy, Aude Oliva.
            <br>
            Vision Science Society, St. Petersburg, Florida (2019)
        </li>
    </ul>

    <hr>

    <h4>Active Community Involvement</h4>
    <ul>
        <li>
            Education Volunteer, <a href="https://www.teji.mit.edu/" target="_blank">The Educational Justice Institute</a> (TEJI) at MIT
            <br>
            I teach MIT computer programming courses to inmates. They learn foundational computer skills that will be essential in their day-to-day lives, continued education, or even careers in tech.
        </li>
        <li>
            Mentor, <a href="https://www.project-short.com/" target="_blank">Project Short</a>
            <br>
            I mentor one prospective graduate student per application cycle through the graduate school application process. I assist with SOPs, mock interviews, networking, and any general advice.
        </li>
    </ul>
 
    <hr>

    <h4>Awards and Achievements</h4>
    <ul>
        <li>
            <b>MIT Open Data Competition - Honorable Mention (2022)</b>
            <br>
            The competition highlights open and publicly accessible data with a large potential for scientific impact. My submission of our
            large-scale fMRI dataset of video event understanding (Algonauts 2021, see above) won runner up against over 70 submissions across all of MIT. 
        </li>
        <li>
            <b>EECS MathWorks Fellowship (2022)</b>
            <br>
            Full graduate student financial support for an academic year awarded to select MIT EECS graduate students using MATLAB to further novel and impactful
            scientific research.
        </li>
        <li>
            <b>Best Biomedical Engineering Senior Design Project (2019)</b>
            <br>
            Awarded best biomedical engineering senior design project out of 42 other projects by Boston University engineering faculty.
            The project delivered a low-latency (~20ms) algorithm to manipulate a mouse's neural signals in real-time. A corresponding scientific publication
            is currently under review ("Theta phase specific modulation of hippocampal memory neurons", see above).
        </li>
    </ul>
  </div>

<footer class="footer">
          <div class="container">
            <p align=center>
              Last updated: Spring 2023. Thank you <a href="http://www.mit.edu/~jcnliang/">Jason Cheuk Nam Liang</a> for the page template.
            </p>
          </div>
</footer>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->


</body></html>